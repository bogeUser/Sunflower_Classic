# AI
## 1. 样本不平衡的处理办法
**在实际生产中，各类别下的样本量几乎是不可能完全相等的，但是一点点的差异基本不会对最后的结果产生影响。但更多的是样本的不均衡。如在欺诈交易识别系统中，属于奇招交易的部分应该是少部分，绝大部分交易都是正产的。如果类别不平衡的比例过大(一般为4:1)，那么分类器会大大地因为数据不平衡而无法满足分类要求。**

**解决办法**
1. 扩大数据集: 更多的数据集往往能够得到更多的特征信息，这也是当遇到样本分布不均的时候首先应该考虑的问题。

2. 尝试其它的评价指标: 准确度评估方式对类别不均衡的分类任务不能胜任，甚至可能误导我们的判断。这时应该考虑使用混淆矩阵(使用一个表格对分类器所预测的类别与其真实类别的样本统计，分别为TP， FN， FP， TN)，精确度，召回率等。

3. 对数据进行重采样:
3.1.欠采样: 随机删除观测数据中足够多的类，使得两个类别找你的相对比例是显著的。虽然这种办法非常简单，但是可能删除的部分包含了观测类的重要信息。
3.2.过采样: 对于不平衡的类，使用拷贝现有的样本方法随机增加观测数量。理想情况下这种办法给了我们足合成采样: 该技术用合成方法得到不平衡类别的观测，该技术与现有的使用近邻分类的方法类似。问题在于当一个类别的观测数量极度稀少时该怎么做。比如用图片分类问题确定一个稀有物种，但是可能只有一张这个稀有物种的图片。
3.1.采用人工合成样本: 一种简单的人工样本数据生产方法便是，对该类下的所有样本每个属性特征空间随机选择一个组成新的样本，即属性随机采样。可以使用经验值对属性值进行随机采样而构造新的人工样本，或者是用类似于朴素贝叶斯方法设置属性之间相互对立进行采样，这样便可得到更多的数据，但是无法保证属性之间的线性关系。
4. 尝试不同的分类算法
5. 尝试对模型进行惩罚
## 2. 数据增强的方法有哪些
**2.1.有监督的数据增强**

**有监督的数据增强即采用预设的数据变换规则，在已有数据的基础上进行数据的扩增，包括单样本数据增强和多样本数据增强。**<br>
2.1.1.单样本数据增强:增强一个样本，全部围绕该样本进行操作，包括几何变换(几何变换包括翻转、旋转、裁剪、变形、缩放等)，颜色变换(包括噪声、模糊、颜色变换、擦除、填充等)。
2.1.2.多样本数据增强:多样本数据增强方法利用多个样本来产生新的样本。常见的多样本数据增强方法有SMOTE SamplePairing Mixup。三者在思路上有相同之处，都是试图将离散样本点连续化来拟合真实样本分布，不过所增加的样本点在特征空间中仍位于小样本点所围成的区域内。如果能够在给定范围外适当插值，也许能够实现更好的数据增强效果。

**2.2.无监督的数据增强**

**无监督的数据增强包括两类**

2.2.1.通过模型学习数据的分布，随机生成与训练数据集分布一致的图片，代表方法是GAN
2.2.2.通过模型，学习出适合当前任务的数据增强方法，代表方法是AutoAugment。
## 3.什么是过拟合
过拟合就是在机器学习或者深度学习建模过程中，训练模型在训练样本中表现得很好，而在验证集以及测试集中表现不佳。这个时候模型的泛化能力很差。
## 4. 过拟合产生的原因
1. 训练集的数据量和模型的复杂度不匹配。训练集的数量小于模型的复杂度。
2. 训练集和测试集的特征分布不同。
3. 样本中噪声数据的干扰过大，大到模型过分记住噪声，反而忽略了真实输入输出之间的关系。
4. 权值学习迭代次数过多，拟合了训练数据中噪声和训练样本中没有代表性的特征。
## 5. 过拟合的解决办法
1. 调整模型的复杂度，使其适合自己训练集的数量级(包括缩小宽度和减小深度)。
2. 训练集越多，过拟合的概率越小，在计算机视觉领域中，曾广的方式是对图像进行旋转、缩放、裁剪、添加噪声等。
3. 参太多，会导致模型的复杂度上升，容易过拟合，同时使得模型的训练误差减小。通过正则化对模型的复杂度带来一定程度上的惩罚。正则化可以保持模型简单，另外，规则项的使用还可以约束模型的性能。
4. 使用dropout、dropout方法是ImageNet提出的一种方法。
5. 提前结束训练。
6. 重新清洗数据，在机器学习或者深度学习中，决定模型性能的上限是特征工程，任何算法或者神经网络的实现都是为了无限接近这个上限。所以，可以通过重新清洗数据来降低过拟合的情况。
## 6. 什么是欠拟合
欠拟合就是在训练集和测试集上都表现得很差。模型没有很好的捕捉到数据特征，不能很多好的拟合数据。同时欠拟合会出现高偏差问题(偏离正确结果)。
## 7. 欠拟合产生的原因
模型的复杂度不够，导致数据的很多特征没有学习到。
## 8. 欠拟合的解决办法
1. 添加其它特征项。
2. 添加多项式特征。例如：将现行的模型通过添加二次项或者三次项使模型使模型的泛化能力更强。
3. 减少正则化参数。正则化是用来防止过拟合的，但是现在模型出现了欠拟合，所以就需要减少正则化参数。
## 9. 正则化原理
正则化是对原函数引入额外的信息，使得目标函数变成原函数+额外项。该额外项可以在不同的时候改变响应的惩罚参数，这样就可以使目标函数产生稀疏的点并向最优解不断靠近而不至于对数据集产生依赖性从而达到降低过拟合的目的。
在正则化因子设置的足够大的情况下，为了使成本函数最小化，权重矩阵W就会被设置以为接近于b的值，直观上相当于消除了很多神经元的影响，那么大的神经网路就会变成一个小的网络。加入正则化后当λ增大，导数就会减小，那么整个损失就会减小，同时减小了模型的复杂度。在损失接近于0的区域内，函数近似线性，所以每层的函数就会近似线性函数，整个网络就会成为一个简单的的近似线性的网络，因此不会发生过拟合。
## 10.常见的激活函数
**神经网络的每个神经元节点接收上一层神经元的输出作为本神经元的输入，并将这个输入值传递给下一层。入股哦不是用激活函数，那么每层节点的输入都是上一层输出的线性函数，很容易验证。并且无论有多少层神经网络，输出的都是线性的组合，这种网络的泛化能力相当有限。所以必须使用非线性的激活函数。**

***10.1.Sigmoid***

特点: 它能把输入的连续值转换为0-1之间的输出，特别的，如果非常大的负数，那么输出的就是0，如果非常大的正数，输出的就是1。

优点: 具有很好的及时性，将线性函数的组合输出为0-1 之间的概率。

缺点: 在神经网络的反向传播时容易导致梯度爆炸和梯度消失，其中梯度爆炸发生的可能性相对较小，但是梯度消失的可能性相对较大，因为Sigmoid函数是把反向传播传回的值映射到0-1之间之间，随着神经网络的层数加深，梯度会越来越小，最终消失。并且Sigmoid的output不是0均值Sigmoid函数中含有幂运算，计算机在求解时相对来讲比较耗时。

公式：
$$
Sigmoid(x) = \frac{1}{1 + e^{-x}}
$$

求导:
$$
Sigmoid^′(x) = \frac {e^{-x}}{(1 + e^{-x})^2} = f(x)(1 - f(x))
$$

函数图像:
![sigmoid](assets/sigmoid.jpg)

***10.2.Tanh***

特点: tanh函数可以把输入值映射到-1到1之间，于Sigmoid函数相比，它的输出均值为0，因此解决了Sigmoid输出均值不为0的问题，使其收敛速度比Sigmoid快，可以减少迭代次数。其缺点也是需要幂运算，计算成本高，而且同样存在梯度消失的问题，因此在Sigmoid函数两边都有趋近于0的情况。

优点: 正负方向与原点对称，输出均值为0，使其收敛速度比Sigmoid快，减少迭代次数。

缺点: 和Sigmoid函数一样，存在梯度消失的问题。

公式: 
$$
tanh(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}
$$

导数:
$$
tanh^′(x) = 1 - tanh(x)^2
$$

函数图像: 
![sigmoid](assets/tanh.jpg)



***10.3.Relu***
特点: relu函数对于小于0的值全部抑制为0，对于正数则直接输出。相比Sigmoid和tanh，relu摒弃了复杂的计算，提高了运算速度。解决了梯度消失的问题，这样可以得到更好的模型。

优点: relu函数在大于0的部分梯度为常数，所以不会产生梯度弥散现象。同时relu函数速度快，只需要判断输入是否大于0。收敛速度远快于Sigmoid和tanh。

缺点: relu函数的争议出现在梯度值小于0的时候，因为relu函数的特点是在梯度小于0时将梯度赋值为0，这个时候就可能导致该神经元不会被其他激活函数激活的现象，如果这个情况发生，那么这个神经元的梯度永远为0。而在实际生产中，如果learning rate很大，那么很有可能网络中40%的神经元都已经dead了。

公式: 
$$
Relu(x) = Max(x, 0) = \begin{cases}
\text{0, x<=0}\\
\text{x, x>0}
\end{cases}
$$

导数:
$$
Relu^′(x) = Max(1, 0) = \begin{cases}
\text{0, x<=0}\\
\text{1, x>0}
\end{cases}
$$


函数图像:
![sigmoid](assets/relu.jpg)

***10.4.SoftMax***
把一堆实数映射到0-1之间，并使他们的和为1，可以理解为对应每个类别的预测概率。

公式:
$$
SoftMax(x) = \frac{e^{x_i}}{\sum_ie^{x_i}}
$$

## 11. 什么是梯度爆炸
梯度爆炸是由于初始化权值W过大，大到乘以激活函数的导数都大于1，随着神经网络深度加深，梯度权值会越来越大，最终导致梯度爆炸。

## 12. 梯度爆炸的解决办法
1. 裁剪梯度，设置一个梯度裁剪阈值，然后在更新梯度的时候，如果梯度超过这个阈值，那么就将其强制在这个范围内以防止梯度爆炸。
2. 数据归一化。
## 13. 什么是梯度消失(梯度弥散)
随着神经网络层数加深，梯度倾向于向越大和越小的两级分化方向前进，当往梯度减小的方向前进时就会导致梯度消失。
通常神经网络所用的激活函数是Sigmoid函数，Sigmoid函数容易引起梯度弥散。因为该函数将整个数值区间映射到0-1，并且这个函数求导之后的数值区间也是0-1。这样经过反向传播之后的数值会更小。再经过神经网络逐层对函数偏导相乘，就会变得越来越小，最终使得loss变为0，从而导致浅层权重得不到更新。
## 14. 梯度消失(梯度弥散)的解决办法
1. 使用relu、leaky-relu等激活函数代替Sigmoid激活函数
2. 用Batch Normalization
3. LSTM的结构设计可以改善RNN中梯度消失的问题
4. 使用预训练的模型进行迁移学习
5. 使用残差网络
## 15. 什么是特征归一化，它与标准化有何区别
标准化: 对数据的分布进行转换，使其符合某种分布(如正态分布)的一种线性特殊变换。
归一化: 对数据的数值范围进行特定的缩放，但不改变其数据分布的一种线性特征变换，一般做法是将数据范围压缩到(0,1)之间

归一化和标准化都能起到提高迭代求解收敛速度的作用，两者之间也确实有相交。但在我看来，标准化应该包括了归一化，而标准化可以映射到更大更多的区间。
## 16. 数据归一化的作用
数据归一化后，更容易正确的收敛到最优解，从而提升模型的精度。在深度学习中，数据归一化还能在一定程度上防止梯度爆炸。
## 17. AuC、RoC、Map、Recall、Precision F1-score
**混淆矩阵**
混淆矩阵衡量的是分类器分类的准确程度(分类可以是单个分类器，也可以是多个分类器)。其中包括4种算法：
- 真阳性(True Positive, TP): 样本的真实类别是正例，并且模型预测的结果也是正例
- 真阴性(True negative, TN): 样本的真实类别是负例，并且模型预测的结果也是负例
- 假阳性(False Positive, FP): 样本的真实类别是负例，但是模型将其预测为正例
- 假阴性(False Negative, FN): 样本的真实类别是正例，但是模型将其预测为负例

**混淆矩阵延伸出的各种评价指标**
- 正确率(Accuracy): 被正确分类的样本比例或数量--(TP + TN) / total
- 错误率(Misclassificaltion / Error Rate): 被错误分类的样本比例或数量--(FP + FN) / total
- 正阳绿(True Positive Rate): 分类器预测为整理的样本占实际正例的数量比例，也叫敏感度(sensitivity)或召回率(recall)，描述了分类器对正例类别的敏感程度
- 假阳率(False Positive Rate): 分类器预测为正例的样本占实际样本数量的比例
- 特异性(sepecificity): 实例是负例，分类器预测结果的类别也是负例的比例
- 精度(Precision): 在所有判断为正例的结果中，真正正例所占的比例
- 流行程度(Prevalence): 正例在样本中所占的比例

**RoC**
ROC是为了形象的衡量分类器的鲁棒性(无论选取多大的阈值，分类都能尽可能的正确)。定义为ROC曲线下方的面积，取值范围在0.5-1之间。
TPR = TP / (TP + FN)
FPR = FP / (FP + TN)
TPR: 表示实际的正样本被模型预测为正样本的概率(越大越好)
FPR: 表示实际的负样本被模型预测为正样本的概率(越小越好)
ROC: 曲线纵坐标是TPR，横坐标是FPR，绘制过程中设置不同的阈值点，当模型预测得分小于阈值的是否是负样本，否者为正样本。

**AuC**
AUC的原始定义是ROC下的面积，计算起来比较麻烦，从ROC的曲线可以看出，AUC不会超过1。同时对于相同的FPR，当TPR越大时，面积越大。即AUC越小。这也就是说、被模型预测为正的样本中，实际的额正样本越多越好，实际的负样本越少越好。从另一个角度说，AUC的物理意义就是：随机选出一个正负样本，模型对正样本的打分大于模型对负样本打分的概率。

由分类输出/结果 得到的一个值，衡量分类效果。AUC曲线下的面积是一个在0-1之间的值，曲线下面积AUC是指ROC曲线下面积。AUC直观反映了ROC曲线表达的分类能力。(AUC=1，代表完美分类器， 0.5<AUC<1，优于随机分类器，0<AUC<0.5差于随机分类器)

AUC的有点: 不受正负样本比例的影响，适合于排序业务，主要衡量一个模型的排序能力。
AUC的缺点: 没有关注模型预测的具体概率值，无法反映正样本内部的排序能力以及负样本内部的排序能力。

**Recall**
召回率 =  预测为真实正例的个数 / 所有真实正样本的个数

**Precision**
准确率 = 预测为真实正例 / 所有被预测为正例样本的个数

**mAP**
即各类别AP的平均值

**F1-Score**
F1-score是召回率和精确率的加权调和平均数，使为了调和召回率和精确率之间的增减反向矛盾。当recall越大时，预测的覆盖率越高，这样precision就会越小，反之亦然。通常，使用F1-score来调和Precision和recall。
## 18. MAE MSE RMSE R-Square
MAE(Mean Absolute Error): 是绝对误差的平均值。可以更好的反应预测值误差的实际情况。

MSE(Mean Square Eerror): 是真实值与预测值的差值的的平方然后求和平均。通过平方的形式便于求导，所以常被用作线性回归的损失函数。
RMSE(Root Mean Square Error): 衡量观测值与真实值之间的偏差。常用来作为机器学习模型预测结果衡量的标准。受异常点影响较大。

R-Square(决定系数): 分母理解为原始数据的离散程度，分子为预测数据和原始数据的误差，二者相除可以消除原始数据离散程度的影响。
## 19. 什么是偏差(bias)、方差(ariable)之间的均衡
偏差(Bias): 反应的是模型在样本上的输出与真实值之间的误差，计算的是模型本省的拟合能力。Bias可能导致模型欠拟合，使其难以具有较高的预测准确性。

方差(Variable): 描述的是通过学习拟合出来的结果自身的不稳定性。

Bias-Variance的分解，本质上是通过在基础数据集中添加偏差、方差和一点由噪声引起的不可约误差，来分级算法上的学习误差。从本质上讲，如果使模型更复杂并添加更多的变量，将会失去一些bais但获得一些Variance。
## 20. 监督学习和非监督学习有何不同
监督学习需要训练数据和测试数据。而无监督学习不需要明确标记数据
## 21. L1、L2正则之间的不同
**L1**
l1是模型各个参数的绝对值之和，L1会趋向于产生少量的特征，而其他的特征都是0.因为最优的参数值很大概率出现在坐标轴上，这样就会导致某一维度的权重为0，从而产生稀疏权重矩阵。
**L2**
l2是力模型各个参数平方和的开方值。l2会选择更多的特征，这些特征都会接近于0。最优的参数值很小概率会出现在坐标轴上，因此每一维的参数都不会是0。

## 22. 模型的精度和模型的性能哪个更重要
这一切都因为模型的准确性仅仅是模型新能的一个子集有关(因为模型性能的评价指标还有如召回率等)，在这点上，有时是一个误导。例如，想在一个拥有百万样本的海量数据集中监测欺诈行为，那么一个更准确的模型很有可能会预测，如果只有极少数案例是欺诈行为，那么根本就不会有欺诈行为。然而，对于预测模型来说，这是一个无用的----一个旨在发现声称没由于欺诈的模型！这样的问题可以证明模型的准确性，但不能证明模型的性能。

# 深度学习
## 1. padding的作用
1. 保持信息边界，如果没有加padding的话，输入图片最边缘的像素点信息只会被卷积核操作一次，但是图像的中间像素点会被扫描很多遍，那么就会在一定程度上降低边界信息的参考程度，但是添加padding后，在实际处理过程中就会从新的边界进行操作，在一定程度上解决这个问题。
2. 利用padding对输入尺寸有差异的图片进行补齐，保证开始输入图片 的尺寸一致。
3. 在卷积神经网络的卷积层加入paddding，可以是的卷积层的输入维度和输出维度保持一致。
4. 卷积神经网路的池化层加入padding，一般都是保持信息边界。
## 2. pooling层如何进行反向传播
**Pooling 层的反向传播需要保证传递到额loss(或者梯度)总和保持以不变。可以分为Max Pooling 和 average Pooling。**

1. Max Pooling: 对某个filter抽取若干个特征值，只取其中最大的那个Pooling层作为保留值，其他的全部抛弃，值最大代表保留这些特征值中最强的。
2. 对某个Filter抽取若干个特征值，计算所有特征值的平均值作为保留。
## 3. Max Pooling 的有点
1. 保证特征的位置与旋转不变性。对于图像处理这种特征性是很要的，但是对于NLP来说特征出现的位置是很重要到。
2. 减少模型参数，在一定程度上能避免过拟合的问题。
3. 可以把变长的输入x整理成固定长度的输入。CNN一般最后都会使用全连接层，神经元的个数需要固定好，但是CNN输出x长度不固定，通过pooling操作，每个filter固定取一个值。有多少个filter，pooling就会有多少个神经元，这样就可以把全连接层的神经元给固定住。
## 4. pooling的作用和缺点
作用: 增大感受野、平移不变性、降低优化难度和参数量。
缺点: 造成梯度稀疏，丢失信息。
## 5. 卷积层和全连接层的区别
1. 全连接层: 全连接层的权重矩阵是固定的，即每次feature map的输入都必须是一定的，所以网络最开始的输入图像尺寸必须固定，才能保证传到全连接层的feature map的大小跟全连接层的权重矩阵匹配。
2. 卷积层:卷积层不需要固定大小，因为他只在局部区域内进行滑动，所以用卷积层取代全连接层。
## 6. 传统seq2seq模型的缺点
传统的seq2seq模型在Encoder和Decoder之间只通过一个固定长度的语义向量C来保持联系。也就是说，Encoder必须要将输入的整个序列的信息都压缩到一个固定长度的向量中，这样存在两个弊端。一是该语义向量C可能无法完全表示整个序列的信息；二是先输入到网络的内容携带的信息回被后输入的信息覆盖，输入的序列长度越长，该现象越严重，从而导致梯度消失。这两个弊端使得Decoder在解码时一开始无法获得输入序列足够多的信息，因此导致解码的精度不够准确。
## 7. Attention的原理
Attention是一种seq2seq模型，包含了Encoder-Decoder两个部分，是Encoder-Decoder模型的一个变种，其中Encoder部分和普通的Encoder模型一样，不通电在Decooder部分，它改变了传统Decoder对每个输入都赋予相同向量的缺点，而是根据矩阵(单词或者像素矩阵)的不同赋予不同的权重。在Encoder过程中，输入不再是固定长度的中间语义，而是一个由不同长度向量构成的序列，Decoder过程根据这个序列自己进行进一步处理。
## 8. Attention的缺点
Attention模型参数都是通过label和预测值的loss反向传播进行更新，没有引入其他监督信息，因此受到的监督有局限，容易对label造成过拟合，并且无法捕捉到具体的位置信息，即没法学习序列中的顺序关系。这个问题在Bert模型中得到改善。
# 机器学习
## 1. KNN和K-Means聚类有何不同
**KNN**
KNN算法(K-nearest Neighbor)是第一个有监督的分类算法，它需要有带标签的学习数据，但是它没有明显的前期训练过程，不需要对数据进行训练。而是在程序开始时把数据加载到内存中，直接开始分类。它的原理是通过计算新数据与训练数据特征之间的距离，然后选取K(k>=1)个距离最近的邻居进行分类或者回归。若k=1，新数据被简单分配给其近邻类。

步骤: 
- 计算测试数据与各个训练数据之间的距离；可以使用欧式距离的公式来进行计算
- 按照距离递增关系进行排序
- 选取距离最小的k个点
- 确定经k个点所在类别的出现频率
- 返回前k个点中出现频率最高的类别作为测试数据的预测分类

优点: 简单、有效
缺点: 计算量比较大，输出的模型可释性不强，需要存储全部的训练样本

**K-Means**
K-Means算法是一种聚类算法，它是很典型的基于距离的聚类算法，采用距离作为相似性评价指标，即认为两个对象的距离越近，其相似度越大。它是使用欧式距离度量的，它可以处理大数据集，而且高效。聚类结果是划分为k个数据集。

原理:
原始的K-Means算法首先随机选取k个点作为初始聚类的中心，然后计算各个数据对象到各个聚类中心的距离，把数据对象归到离它最近的那个聚类中心所在的类；调整后的新类计算新类的聚类中心，如果相邻两次聚类中心没有任何变化，说明数据对象调整结束，聚类准则函数已经收敛。在每次迭代中都要考察每个样本分类是否正确，若不正确，就要调整。在全部数据调整完后，再修改聚类中心，进入下一次迭代。如果在一次迭代算法中，所有的数据对象被正确分类，则不会有调整，聚类中心也不会有任何变化，这标志着聚类函数已经收敛，算法结束。

**区别**
KNN是分类算法，属于监督算法，喂给它的数据是带标签的完全正确的数据。它没有明显的训练过程。
K-Means是聚类算法，属于非监督学习算法，喂给它的数据集是无标签的，杂乱无章的数据，经过聚类后才变得有点顺序，有明显的训练过程。
## 2. 什么是贝叶斯定理？它在机器学习中有何作用
贝叶斯是根据一种数据的内容变化更新概率的方法。贝叶斯的核心是将两种不同的分布(似然和先验)组合成一个”更智能的“分布(即后验)。贝叶斯是一种机器学习思想，而不是简单的套用公式。而且在用朴素贝叶斯方式进行机器学习时还经常要使用一些辅助手段。

**公式:**
$$
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
$$
其中:
- P(A)表示A出现的概率
- P(B|A)表示事件A发生的情况下，事件B发生的概率
- P(A|B)表示事件B发生的情况下，事件A发生的概率

## 3. 概率和似然有何区别
概率描述了已知参数时，随机变量的输出结果；似然则用来描述已知随机变量输出结果时，未知参数的可能取值。例如，对于“一枚正反的硬币抛10次”这种事件，可以问硬币落地时十次都是正面向上的概率是多少；而对于“一枚硬币上抛十次”,则可以问，这枚硬币正反面对称的似然度是多少。

- 似然是给定概率条件下，对观察对象的预测，也就是概率的逆反。
- 概率表达给定θ下样本随机向量X=x的可能性，而似然表达给定样本X=x下参数θ(相对于另外的参数$$θ_2$$)为真实性的可能性。一般对随机变量的取值谈概率。在贝叶斯统计的角度下，参数是一个实数而非随机变量，所以一般不谈概率，而说是似然。

## 4. 什么是傅里叶变换
傅里叶变换是将一般函数分解成堆成函数叠加的一般方法。傅里叶变化找到一组循环速度、振幅和相位，以及匹配任何时间信号。傅里叶变换就将信号从时间阈转换成频率阈。这是从音频信号或其他时间序列中提取特征的一种常见方法。

## 5. 如何对决策树进行剪枝
- 决策树每个节点选择某个特征作为划分节点的判断依据是熵值。根节点的划分是通过信息增益进行划分的，第一步先根据标签计算系统熵值，第二步根据每个特征值计算在以该特征为根节点的情况下的信息增益，信息增益作为根节点。
- 剪枝是在决策树中，为了降低模型的复杂度，提高决策树的预测精度，去除预测能力较弱的分支的一种操作，可以是自下而上的自上而下的，方法包括减少错误修剪和成本复杂度修剪。
- 预剪枝: 预剪枝的思想是在数种节点进行生长之前，先计算当前划分是否能提升模型的泛化能力，如果不能的话，那么就不再进行子树生长。一般来说，预剪枝对于何时停止决策树的生长有几种办法。1. 当决策树达到一定的深度时，停止生长。2. 当达到当前节点的样本数量小于某个阈值时，停止树的生长。3. 计算决策树每次分裂丢测试集的准确度是否提升，当没有提升或者提升度小于某个阈值时，停止决策树生长。预剪枝具有思想直接、算法简单、效率高等特点，适合解决大规模的问题，但是如何准确地轨迹何时停止决策树的生长，针对不同问题应该分别考虑，需要一定的判断经验。
- 后剪枝: 后剪枝的思想其实就是让算法生成一颗完全生长的决策树，然后从底层向上计算是否剪枝，如果需要剪枝，剪枝过程就是把子树删除，用一个叶子节点替代，该节点的类别按照多数投票的方法进行判断。同样的，后剪枝也可以通过在测试集上准确进行判断，如果剪枝后的准确率有所提升或者没有降低，那么就可以进行剪枝。一般来说，后剪枝通常得到的决策树泛化能力更好，但是时间上开销更大。






