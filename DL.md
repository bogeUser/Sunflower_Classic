# 深度学习
## 1. padding的作用
1. 保持信息边界，如果没有加padding的话，输入图片最边缘的像素点信息只会被卷积核操作一次，但是图像的中间像素点会被扫描很多遍，那么就会在一定程度上降低边界信息的参考程度，但是添加padding后，在实际处理过程中就会从新的边界进行操作，在一定程度上解决这个问题。
2. 利用padding对输入尺寸有差异的图片进行补齐，保证开始输入图片 的尺寸一致。
3. 在卷积神经网络的卷积层加入paddding，可以是的卷积层的输入维度和输出维度保持一致。
4. 卷积神经网路的池化层加入padding，一般都是保持信息边界。
## 2. pooling层如何进行反向传播
**Pooling 层的反向传播需要保证传递到额loss(或者梯度)总和保持以不变。可以分为Max Pooling 和 average Pooling。**

1. Max Pooling: 对某个filter抽取若干个特征值，只取其中最大的那个Pooling层作为保留值，其他的全部抛弃，值最大代表保留这些特征值中最强的。
2. 对某个Filter抽取若干个特征值，计算所有特征值的平均值作为保留。
## 3. Max Pooling 的有点
1. 保证特征的位置与旋转不变性。对于图像处理这种特征性是很要的，但是对于NLP来说特征出现的位置是很重要到。
2. 减少模型参数，在一定程度上能避免过拟合的问题。
3. 可以把变长的输入x整理成固定长度的输入。CNN一般最后都会使用全连接层，神经元的个数需要固定好，但是CNN输出x长度不固定，通过pooling操作，每个filter固定取一个值。有多少个filter，pooling就会有多少个神经元，这样就可以把全连接层的神经元给固定住。
## 4. pooling的作用和缺点
作用: 增大感受野、平移不变性、降低优化难度和参数量。
缺点: 造成梯度稀疏，丢失信息。
## 5. 卷积层和全连接层的区别
1. 全连接层: 全连接层的权重矩阵是固定的，即每次feature map的输入都必须是一定的，所以网络最开始的输入图像尺寸必须固定，才能保证传到全连接层的feature map的大小跟全连接层的权重矩阵匹配。
2. 卷积层:卷积层不需要固定大小，因为他只在局部区域内进行滑动，所以用卷积层取代全连接层。
## 6. 传统seq2seq模型的缺点
传统的seq2seq模型在Encoder和Decoder之间只通过一个固定长度的语义向量C来保持联系。也就是说，Encoder必须要将输入的整个序列的信息都压缩到一个固定长度的向量中，这样存在两个弊端。一是该语义向量C可能无法完全表示整个序列的信息；二是先输入到网络的内容携带的信息回被后输入的信息覆盖，输入的序列长度越长，该现象越严重，从而导致梯度消失。这两个弊端使得Decoder在解码时一开始无法获得输入序列足够多的信息，因此导致解码的精度不够准确。
## 7. Attention的原理
Attention是一种seq2seq模型，包含了Encoder-Decoder两个部分，是Encoder-Decoder模型的一个变种，其中Encoder部分和普通的Encoder模型一样，不通电在Decooder部分，它改变了传统Decoder对每个输入都赋予相同向量的缺点，而是根据矩阵(单词或者像素矩阵)的不同赋予不同的权重。在Encoder过程中，输入不再是固定长度的中间语义，而是一个由不同长度向量构成的序列，Decoder过程根据这个序列自己进行进一步处理。

## 8. Attention的缺点
Attention模型参数都是通过label和预测值的loss反向传播进行更新，没有引入其他监督信息，因此受到的监督有局限，容易对label造成过拟合，并且无法捕捉到具体的位置信息，即没法学习序列中的顺序关系。这个问题在Bert模型中得到改善。

## 9. 利用梯度下降法训练神经网络模型，发现模型loss不变，可能有哪些问题，怎么解决
可能原因: 很有可能是梯度消失了，它表示神经网络迭代更新时，有些权重不更新的现象。
解决办法: 改变激活函数，改变权值的初始化值。

## 10. 残差网络为什么能做到很深层
神经网络在反向传播过程中要不断地传播梯度，而当网路加深时，梯度在逐层的传播过程中逐渐衰减，导致无法对前面网络层的权重进行有效调整。残差网络中，加入了shor connectionis为梯度带来了一个直接向前面层全波的通道，缓解了梯度的减小问题。

## 11. 卷积神经网络中空洞卷积的作用是什么
空洞卷积也叫扩张卷积，在保持参数不变的情况下增大了卷积核的感受野，同时它可以保证输出的特征映射的大小保持不变。一个扩张为2的3*3卷积核，感受野于5的卷积核相同，但参数数量仅仅为9个。

## 12. 解释下卷积神经网络中的感受野
在卷积神经网络中，感受野的定义是，卷积神经网络每一层输出的特征图上的像素点在原始图像上映射的区域大小。

## 13. 注意力机制在深度学习中的作用什么，有哪些场景会使用
深度学习中的注意力机制从本质上来讲和人类的选择性视觉注意力机制类似，核心目标是从大量信息中有选择的筛选出少量重要信息并聚焦到这些重要信息上，忽略大多不重要的信息。

## 14. 解释批量归一化的原理
在数据送如到神经网络某一层进行处理之前，对数据做归一化。按照训练样本的批量进行处理，先减掉这批样本的均值，然后除以标准差，然后进行缩放和平移。缩放和平移参数同训练得到。预测时使用训练时确定的这些值来计算。

## 15. 请简要介绍一下TensorFlow的计算图
TensorFlow的计算图也叫数据流图。数据流图用"节点" 和 "线" 的有向图来描述数学计算。"节点"一般用来表示施加的数学操作，但也可以表示数据输入的起点/输出的终点。或者是读取/写入持久变量的终点。"线"表示"节点"之间的输入/输出关系。这些数据"线"可以运输。"size可动态调整"，即"张量"。张量从图中流过的直观图像是这个工具取名为TensorFlow的原因。一旦输入端的所有张量准备好，节点将被分配到各种计算设备完成异步并行地执行运算。

## 16. 你有哪些深度学习调参经验
CNN的调参主要是优化函数、embedding的维度还有残差网路的层数几个方面。优化函数方面有两个选择。sgd和adam，相对来说，adam要简单很多，不需要设置参数，效果也还不错。embedding随着维度的增大会出现一个最大值，也就是开始时随维度的增加效果逐渐变好，到了一个点，而后随着维度的增加，效果会变差。残差网路的层数与embedding的维度有关系，随着层数的增加，效果变化也是一个凸函数。另外还有激活函数、dropout层和batchnormalize层的使用。激活函数推荐使用Relu，dropout层数不宜设置过大，过大会导致不收敛，调节步长可以是0.05，一般调整到0.4或者0.5就可以找到最佳。

## 17. 为什么不同的机器学习领域都可以使用CNN、CNN解决了这些领域的哪些共性问题？如何解决的
CNN的关键是卷积运算，卷积核与卷积输入层进行局部链接可以获得整个输入的局部特征信息或者说是每个输入特征的组合特征。所以CNN的本质是完成了特征提取或者说是对原始特征的特征组合工作，从而增加模型的表达能力。不同领域的机器学习都是通过数据的特征进行建模，，从而解决该领域的问题。所以CNN解决了不同领域的特征提取问题，所用的方法是基于局部连接/权值共享/池化操作/多层次结构化。

## 18. 为什么LSTM模型中既存在Sigmoid又存在tanh，而不是统一使用Sigmoid或者tanh，这样做的目的是什么
LSTM在用到Sigmoid函数的地方都是用在各种控制门上，用于产生0-1之间的值，目的是可以让神经元决定对过去输入和前一个状态的取舍，如果为0则全部丢弃，如果为1则将数据全部传入后续的计算。而tanh的输出范围是[-1, 1]。

## 19. 什么样的数据集不适合用于深度学习
- 数据集太小，数据样本不足
- 数据集没有局部相关性，目前深度学习表现较好的领域主要是图像/语音/自然语言处理领域。这些领域的一个共性是局部相关性。图像中像素组成物体，语音信号中音位组合成单词，文本数据中单词组合成句子，这些特征元素的组合一旦被打乱，表示的含义同时也被改变。对于没有这样局部相关性的数据集，不适用于深度学习算法进行处理。
- 例如: 预测一个人的健康情况，相关的参数会有年龄、职业、收入，家庭情况等各种元素，将这些元素打乱，并不会影响相关结果。

## 20. 神经网络中激活函数的真正意义，一个激活函数需要具备哪些必要性，哪些属性是好的但没必要
- 非线性: 即导数不是常数。这个条件是多层神经网络的基础，保证多层网络不退化成单层线性网络。这也是激活函数的意义所在。
- 几乎处处可微: 可微性保证了在优化梯度的可计算性。传统的激活函数Sigmoid等满足处处可微。对于分段线性函数，比如Relu，只满足几乎处处(仅在有限个点处不可微)。对于sgd算法来说。由于几乎不可能收敛到梯度接近零的位置，有限的不可微点对于优化结果不会有很大的影响。
- 计算简单: 非线性函数有很多。极端来说，一个多层神经网络也可以作为一个非线性函数，类似于Network In Network中把他当做卷积操作的做法。但激活函数在神经网络前向的计算次数与神经元的个数成正比，因此简单的线性函数自然更适合激活函数。这也是Relu之流比Exp等操作的激活函数更受欢饮的一个原因。

## 21. 梯度下降的神经网络容易收敛到局部最优，为什么应用广泛
深度神经网络"容易收敛到局部最优"，很可能是一种假象，实际情况是，可能从来没有找到过"局部最优"，跟别说全局最优了。很多人的一种看法是"局部最优是神经网络优化的主要难点"。这源于一维优化问题的直观想象。在单变量的情况下，优化问题最直观的困难就是有很多局部极值。

## 22. 简单说说CNN常用的几个模型
- **ALexNet:** 引入了Relu和dropout，引入了数据增强、池化相互间的覆盖，三个卷积一个最大池化+三个全连接层。
- **VGGNet**: 采用1*1和3*3的卷积核以及2*2的最大池化层使得层数变得更深。常用VGGNet-16和VGGNet-19。
- **GoogleInception Net**: 这个在控制了计算量和参数量的同时，获得了笔记好的分类性能，和上面的几个相比有几个大的该井 1.去除了最后面的全连接层，而是用一个全局平均池化层来取代他。2. 引入了Inception Module，这是一个4个分支结合的结构。所有的分支都用到了1*1的卷积，这是因为1*1性价比很高，可以用很少的参数达到非线性和特征变换。3. Inception V2第二版将所有的5*5变成3*3，而且提出了著名的BatchNormalization。4. Inception V3第三版，把较大的二位卷积拆成两个较小的一维卷积，加速运算，减少过拟合，通知还更改了Inception Module的结构。
- **Resnet**: 引入了高速公路结构，可以让神经网络变得非常深。ResNet第二版将Relu激活函数变成y=x的线性函数。

## 23. 如何确定是否出现梯度爆炸
**训练过程中出现梯度爆炸会伴随一些细微的信号如:**
- 模型无法从训练数据中获得更新
- 模型不稳定，导致更新过程中的损失出现显著变化
- 训练过程中，模型的损失变成NaN
- 训练过程中模型的梯度快速变大
- 训练过程中模型的权重变成NaN
- 训练过程中，每个节点和层的误差梯度值持续超过1.0

## 24. 介绍一下RNN
- RNN的目的是用来处理序列数据。在传统神经网络模型中，是从输入层到隐藏层再到输出层，层与层之间是全连接的，每层之间的节点是无连接的。但是这种普通的神经网络对于很多问题却无能为力。例如，预测句子的下一个单词是什么，一般需要用到前面的单词，因为一个句子中前后单词并不是独立的。
- RNN之所以成为神经网络，即一个序列当前的输出与前面的输出也有关。具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐层之间节点不再无连接而是有链接的，并且隐层的输入不仅包括输入层的输出还包括上一个时刻隐层的输出。

## 25. 介绍几种RNN的经典模型结构
**RNN是循环神经网络，主要处理时间序列的数据。RNN的主要结构是利用当前时刻的输入和当前时刻前一个时刻的输出组欧威当前时刻的输出及诶过。这种结构可能出现短时记忆的情况。就是输欧如果只能理解有限长度的序列数据，对于较长范围内的有用信息往往不能很好的利用起来。并且这种歌结构在进行反向传播过程中由于层数加深很可能会导致梯度弥散和梯度爆炸问题。**

- **LSTM**: LSTM是在RNN的基础上加了三个门，分别是遗忘门，输入门，输出门。遗忘门作用于上一个时刻的输出结果上，一般使用Sigmoid激活函数。遗忘门的作用域为0-1之间。当取值为0的时候，遗忘门关闭，即不接收上一个时刻的输入。输入门用于控制LSTM对输入的接收程度。当神经网络接收了当前时刻和当前时刻的前一个时刻输出结果经过线性变化并使用tanh激活函数将输入标准化到[-1, 1]区间，这时候的输出结果并不会立即被记忆，而是需要经过输入门，输入门的取值范围在0-1之间，当取值为0时，不接收任何新的输入。完成了上述输入门和遗忘门的计算后的值不会立即被作为输出值，而是要经过输出门的计算，输出门的取值范围同样在0-1之间，当取值为0时，输出关闭。LSTM的记忆完全被阻断。此时输出为0的向量。LSTM相较于普通的RNN具有更长的记忆力，在大部分序列任务上都取得了比基础RNN模型更好的性能表现，更重要的是，LSTM解决了部分梯度弥散现象。但是LSTM相对比较复杂，计算代价较高，模型的参数量比较大。

- **GRU**: GRU把内部状态向量和输出向量合并统一，将门控制数量减少到2个，分别是复位门和更新门。复位门用于上一个时间戳的状态进入到GRUde量。控制的位置在上一个时间戳和当前时刻的输入结合之后，使得Sigmoid函数作为激活函数，取值范围为0-1，当取值为0时，不接收上一个时间戳的输入，当取值为1时，上一个时间戳和当前时刻的输入共同产生新的输入。更新门用于控制上一个时间戳状态和新输入对新状态的控制，采用Sigmoid函数，取值为0时，更新值全部来自上一个时间戳，当取值为1时，全部来自新输入的值。

- **Seq2Seq**: 是一种Encoder Decoder的框架模型，其中Encoder和Decoder分别使用一个LSTM结构的网络。模型首先将输入数据进行编码，然后会将当前时刻的输出值作为下一个时刻的输入值，那么如果在某一个时刻的输出值误差较大甚至是错误的，那么就会导致后面的结果都不正确，从而引发蝴蝶效应。

- **Attention**: Attention模型机注意力机制，Encoder-Decoder模型的一个变种，其中Encoder部分和普通的Encoder模型一样，不同点在Decoder定长度的中间向量，此为编码。然后再将该向量解码后的数据通过类似于softmax函数的值输出。但是该模型有几个比较大的缺点，一是在Encoder过程中只能Encoder为固定长度的中间向量。这就会导致在Encoder的过程中可能导致信息丢失从而降低编码的准确率。二是在Seq2Seq结构中的oder部分，它改变了传统Decoder对每个输入都赋予相同向量的缺点，而是个根据矩阵(单词或者像素矩阵)的不同赋予不同的权重。在Encoder过程中，输入不再是固定长度的中间语义，而是由一个不同长度向量构成的序列，Decoder过程根据这个序列的权重进一步处理。

- **TransFormer**: Transform模型也是Encoder-Decoder的一个变种，于传统Encoder-Decoder不同的是在Transform中，Encoder中都包含了多层的encoder-layer层，每层encoder-layer包含一个Self-Attentino和一个Feed Forward。Decoder同样包含了多个decoder-layer层，和Encoder中的encoder-layer不同的是，在Encoder中每层encoder-layer层包含一个Self-Attention、一个Encoder-Decoder Attention和一个feed forward层。

## 26. GRU是什么，GRU对LSTM做了哪些改动
GRU是循环神经网络的一种。它有两个门(update和reset)；LSTM有三个门(forget，input，output)，GRU直接将hidden state传给了下一个单元，而LSTM用meimory cell 把 hidden state包装起来。

## 27. 如何解决深度学习中模型训练效果不佳的情况
**如果模型训练效果不好，可以先考察一下几个方面:**
- 选择合适的损失函数: 神经没网络的损失函数是非凸的，有多个局部最低点。非凸函数是凹凸不平的，但是不同的损失函数凹凸起伏程度不同，例如平方误差损失和交叉熵误差损失，后者起伏更大，且后者更容易找到一个可用的最低点，从而达到优化的目的。
- 选择合适的Mini-batch size: 采用合适的Mini-batch进行学习，使用Mini-batch的方法进行学习，一方面可以减少计算量，一方面有助于跳出局部最优点。因此要使用Mini-batch。更进一步，batch的选择非常重要，batch取太大会陷入局部最小值，batch取太小会抖动很厉害，因此要选择一个合适的batch-size

## 28. 梯度下降算法的正确的步骤是什么
1. 用随机值初始化权重和偏差
2. 把输入传入到网络，取得输出值
3. 计算预测值和真实值之间的误差
4. 对每个产生误差的神经元，调整相应的(权重)值以减小误差
5. 重复迭代，直至得到网络权重的最佳值

## 29. 深度神经网络和深度学习的区别
- 机器学习是很多种方法和模型的总称
- 神经网络是一种机器学习模型，可以说是目前最火的一种
- 深度神经网络就是层数比较多的神经网络
- 深度学习就是使用了深度神经网络的机器学习

## 30. 当训练深度学习模型时，Epoch、batch和Iteration概念意味着什么
- **Epoch**: 表示整个数据集迭代了一次
- **Batch**: 指每次训练不能将整个训练集移入神经网络，因此将数据集分成几批小的数据集
- **iteration**: 是运行一个epoch所需的批次数。假设有10000个数据集，batch size 为200。然后一个epoch将包含50个iteration。

## 31. 生成器的概念是什么，什么时候使用它

## 32. word2vec、skip-gram的原理，如何加速word2vec
Word2vec是一种语言模型(语言模型是用来统计一个句子/单词的概率模型，它通过基于第一个语料库来构建。)，是用来生成词向量的工具，是将单词映射到向量，也即是将单词映射为数值型的向量，可以直接在神经网络中运行。它是从大量文本语料中以无监督方式学习语义知识的模型。其计算原理是通过bayes公式计算句子中单词的联合概率。但是在实际训练过程中，由于语料库的量级以及组合的原因计算逻量会非常大，一般计算-gram模型，也就是计算满足实际需求的少量组合，这样做的目的是减少参数量，从而减少模型的训练时间。而在实际开发过程中，很少会自己训练，一般是从网上直接下载已经训练好的语言模型，然后运行在类似于pytorch、TensorFlow等框架中，可以直接得出相应的词向量。在Word2vec中主要有skip-gram和cbow两种模型，这两个模型最大的区别是skip-gram模型给定input word预测上下文，cbow是给定上下文预测input word。

## 33. dropout和batch normalization的原理
- dropout是在CNN中防止过拟合的一种正则化方法。在一次训练迭代中，对每一层中的神经元以概率P随机剔除，用剩余(1-p)乘以神经元总数个神经元所构成的网络来训练本次迭代中的数据。
- dropout的主要目的是为了降低过拟合。因为在设计网络时，设定的每层神经元代表一个学习到的中间特征(即几个权值的组合)，网络所有神经元共同作用来表征输入数据的特定属性。当相对于网络的复杂程度而言数据量过小时，出现过拟合现象，那么显然这个时候各神经元的特征相互之间存在许多重复的冗余。而dropout的知己作用就是减少中间特征的数量，从而减少冗余，即增加每个层各个特征之间的正交性。
- **dropout有效的原因**: 加入了dropout后，输入的特征都存在被清除的可能，所有该神经元不会再特别依赖任何一个输入特征，也就是不会各任何一个输入特征设置太大的权重，通过传播，dropout将产生和L2正则化相同的收缩权重效果。对于不同的层，设置的keep_prob大小也不一致，神经元较少的层，会设置keep_prob为1.0，而神经元多的层则会设置比较小keep_prob。通常在计算机视觉领域，图像拥有更多的特征，场景容易过拟合，效果被实验人员证明是很不错的。
- **dropout的缺点**: dropout的缺点是成本函数无法被明确定义，因为每次会随机消除一部分神经元，所以参数也无法确定，在反向传播的时候带来计算上的麻烦。也就是无法保证当前网络时否损失函数下降的，如果要使用dropout，会先关闭这个才送，保证损失函数是单调下降大的，确定网络没有问题，再次打开dropout才会有效。
- **batch normalization的原理**: 在训练神经网络之前，都需要对数据做一个归一化处理，只要网络在前面几层发生微小改变，那么后面几层就会被积累放大下去。一旦网络某一层的输入数据的分布发生变化，那么这一层网络就需要去适应新的数据分布，所以如果训练过程中，训练数据的分布一直在变化，那么将会影响网络的训练速度。神经网络一旦训练起来，那么参数就会发生更新，除了输入层的数据外(因为输入层的数据在数据预处理阶段就已经人为的进行归一化处理了)，后面网络每一层的输入数据分布是一直在变化的，因为在训练的时候，前面层训练参数的更新将导致后面层输入数据的变化。因此会引起后面每一层输入数据分布的改变。这种现象称为内部协变量偏移。而BN(batch normalization)和激活函数层、卷积层、池化层、全连接层一样属于神经网络的一个层。其原理就是在每一层输入之前插入一个归一化层，也就是在进入神经网络之前先做一次归一化处理，然后再进入神经网络。但是这个归一化和普通的归一化有差别，它使用的是变换重构的方式，引入了γ、β两个参数，目的是不破坏上一层学习到的特征。

## 34. 为什么批标准化能够使得网络优化过程变得简单
在网络当中，数据的分布会随着不同的数据集改变，BN层的作用就是加上Internal Covariate shift所带来的影响，让模型变得更加健壮，鲁棒性更强。即时输入值改变了，由于BN的作用，使得均值和方差保持固定，限制了在前层的参数更新对数值分布的影响，因此后层的学习变得更容易一些。BN减少了各层W和b之间的耦合性，让各层更加独立，实现自我训练学习的效果。

## 35. SGD、Adagrad、Adam原理以及各自的优势
- **梯度下降算法原理**: 某一个函数在某一点上的导数即为该函数在该点的梯度，那么沿函数导数的方向取最大值即为该函数变化最快的方向。梯度下降算法是找出函数的最小值，那么将该方法反过来即能找到该函数的最小值。梯度下降法在计算梯度时需要随机初始化一个参数，然后通过梯度下降的方式慢慢的逼近最优点，更新的方式就是沿着梯度最大的方向前进，这个方式可以以最快的方式达到想要达到的最优节点。慢慢逼近的过程需要设置一个步长，也就是每次逼近多大的距离，这个距离需要适中，如果设置的太小，虽然最终会收敛，但是这样的话时间成本会比较大；如果太大则有可能错过最优解，导致学习不会收敛，或者偏离学习想要的最优点。同时学习的步长可以在学习的过程中动态调整，在一开始的时候设置得稍微大一些，随着学习的深入，这个补偿需要慢慢的减小。
- **SGD**: 随机梯度下降算法第一步就是随机化整个数据集。每次迭代仅选择一个训练样本去计算函数的梯度，然后跟新参数。即使是大规模数据集，随机梯度下降算法也会很快收敛。随机梯度下降法得出的结果准确性可能不是最好的，但计算速度很快。
- **Adagrad**: 自适应梯度优化算法的学习率是不断变化的，但是每个维度都相同。它的学习方式是通过累加平方梯度的方式来改变学习率。这使得在平缓的地方，由于梯度小，对应学习的下降幅度就会小；对于陡峭的地方，由于梯度值大。对应的学习率就会相对的大幅度下降，使得更加平缓，从而加快训练速度。但是该算法有个缺点就是Adagrad会记录之前所有的梯度之和，这使得这个结果会越来越大，从而使得后面的学习率会无限接近于0，导致权值无法更新。为了改善这点，可以使用RMSProp算法，RMSProp算法会逐渐遗忘过去的梯度，在做加法运算时将新梯度的信息更多的反映出来。
- **Adam**: Adam算法是一种随机梯度下降算法的扩展。不同的是SGD保持的时一个单一的学习率，永远所有权重更新，并且在训练过程中学习率不会改变。而Adam算法是将AdaGrand和RMSProp结合。该算法有三个参数，alpha:学习率,beta1:第一次估计的指数衰减率，beta2:第二次估计的指数衰减率，epsilon:是一个非常小的数字，可以防止任何实施中被0划分。该算法计算了梯度和平方梯度的指数移动平均值，并且参数beta1和beta2控制移动平均衰减率。

## 36. Attention机制里面的q、k、v分别代表什么
- **Q**: 指的是query，相当于Decoder的内容
- **K**: 指的是key，相当于encoder的内容
- **V**: 指的是value，相当于encoder的内容
- **q和k对齐了解码端和编码端的信息相似度，相似度的值进行归一化后会生成对齐概率值(注意力值)。v对应的是encoder的内容，qk完成权重重新计算，v复制重编码**

## 37. 为什么self-Attention可以替代Seq2Seq
- Seq2Seq最大的问题在于将Encoder端的所有信息压缩到一个固定长度的向量中，饼干将其作为Decoder端首个状态的输入，来预测Decoder端第一个单词(token)的隐藏状态。在输入序列比较长的时候，这样做显然会损失Encoder端的很多信息，而且这样一股脑的把固定向量送入decoder端，decoder端不能够关注到其想要关注的信息
- self-Attention让源序列和目标序列首先自关联起来，这样的话，源序列和目标序列自身的embedding表示所蕴含的信息更加丰富，而且后续的FFN层也增强的模型的表达能力，并且Transform并行计算的能力是远远超过Seq2Seq系列的模型

## 38. FastText和CBOW模型的相同点和不同点
- **相同点**: 两种模型都是基于Hierarchical softmax，都是三层架构（输入层、隐藏层、输出层）
- **不同点**：
    - CBOW模型基于N-granm模型和BOW模型，此模型将W(t-N+1)....W(t-1)W(t-N+1)....W(t-1)作为输入，去预测W(t)，fastText的模型则是将整个文本作为特征去预测文本的类别
    - CBOW是词袋模型，而fastText还加入了一个N-gram特征
    - word2vec的输出层，对应的是每个term，计算某个term概率最大；而fasttext输出层对应的是分类的label
    - word2vec的输入层，是context window 内的term；而fastText对应的整个sentence的内容包括term，也包括N-gram的内容。

## 39. 卷积神经网络在max pooling处怎样处理反向传播误差
**无论max pooling还是mean pooling，都没有需要学习的参数。因此，在卷积神经网络的训练中，pooling层需要做的仅仅是将误差传递到上一层，而没有梯度计算**
- **max pooling**: 对于max pooling，下一层的误差项的值会原封不动的传递到上一层对应区块中最大值所对应的神经元，而其它神经元的误差项都是0
- **mean pooling**: 对于mean pooling，下一层的误差项的值会平均分配到上一层对应区块中的所有神经元

## 40. 深度学习中压缩模型的方法
- **设计轻量级的模型(SqueezeNet，MobileNet，ShuffleNet等)**: 不需要压缩模型
- **模型结构/内存优化**: 剪枝、权值量化等
- **模型蒸馏**

## 41. 如何判断一个神经网络模型是记忆还是泛化

## 42. 为什么需要Batch-size
当数据集较小时可采用全数据集的形式，因为全数据集确定的方向能更好的代表样本总体，从而更准确地朝向极值所在的方向。当数据集的量相对比较大时，一次性把所有的数据输入进网络，可能会导致因为内存不够而导致内存爆炸。如果采用一次一条数据的方式进行训练，又无法充分利用硬件资源，而且会浪费大量的时间。所以选择每次输入一定量的数据进入网络进行训练，这样能最大限度地利用硬件资源，提高训练速度。相较于一次一条数据，使用适当的batch-size，有利于更快更准的找到梯度的方向。

## 43. 如何选择batch-size

## 44. 在合理范围内，增大Batch-size有何好处

## 45. 盲目增大Batch-size有何坏处

## 46. 调整Batch-size对训练有何影响

## 47. 空洞卷积
在相同感受野的情况下，使用空洞卷积可以得到更大的特征图，可以获得更加密集的数据。在相同感受野的情况下，更大的特征图有助于在目标检测和目标分割的任务中对小物体的识别分割效果。

## 48. RCNN Fast-RCNN Faster-RCNN的区别
**RCNN**
RCNN采用SS算法(selective search)进行目标检测，它是一种基于区域(Region Proposal)的方法。SS方法会先找出一个区域集，然后计算区域集里面每个相邻区域的相似度，相似度的计算方法主要考虑颜色，纹理，尺寸，交叠四个方面的特征，然后划分不同的区域。
- 算法流程:首先使用SS算法生成2000个候选区域，然后将2000个候选区域转成相同大小的图片，然后将图片放入任意的卷积网络中作特征提取(比如 Google Net、VGG16)。在卷积神经网络中完成特征提取之后需要做两个事情，分别是分类器会回归器。其中分类用得是SVM分类器，回归的话主要是将目标框和标间记性对比然后做出调整，使得更接近于真是的质保住。
- 步骤:
    - 1. 选择一个分类器模型(如AlexNet，VGGNet等)
    - 2. 去掉最后一个全连接层，将分类数改为N + 1(N为分类数，1表示背景)
    - 3. 对模型进行微调(主要目的是优化卷积层和池化层的参数)
    - 4. 训练SVM分类器模型(二分类)来判断这个候选框里面的物体类别，总共要训练N+1个分类器(比如该分类器用来识别狗的话就判断是不是和其它物体这样一个二分类器模型)。然后将2000个候选框逐个放到分类器中记性判断，得到分类结果。
    - 5. 在训练分类器模型的同时需要训练一个回归器模型，模型主要用于生成目标库的候选区域，主要有4组参数，分别是候选框的中心点坐标，候选框的宽度和高度。然后计算候选框和真实框之间的IOU(交并比)，如果该IOU大于一定的阈值，则认为框到的是真实的物体。小于该阈值的候选框会背认为是负样本，会传回给SVM，在下次训练的时候作为SVM的负样本进行训练。
- 流程：图片--->通过SS算法生成2000个候选框--->将候选区域调整成相同大小的图片--->将图片送入到GoogleNet网络中，训练SVM分类器进行分类，分类器的训练个数为N+1(N为目标个数，1为背景)--->将得到的结果训练回归器得到(dx, dy, dw, ddh)四个结果，并通过IOU值判断该框内的物体是否满足任务需求。

**Fast-RCNN**
SPP-Net算法最大的改进就是只需要将原图做一次卷积操作，就可以得到每个候选区域的特征，SPP-Net的图像检测速度大约比RCNN提升了100倍。
Fast-RCNN使用SPP-Net算法只需要做一次卷积的设计思想，使Fast-RCNN算法只需要做一次卷积，然后用SS算法生成2000个候选区域，然后使用特征映射的方法经各自的特征映射到各自的特征图上。然后将不同大小的特征图做一次roi-pooling(其实就是金字塔池化层的一种简单化形式)，即将各个候选区图大小分成若干个相同的大小，得到相同维度的数据，然后传入到全连接层分别做回归和分类，此处的分类器使用的是softmax算法。
- 流程: 图片--->通过SS(selective search)算法生成2000个候选区域--->通过roi-pooling算法得到各个区域最大的一个特征值--->将所有的特征值传入达到GoogleNet网络中--->使用softmax分类器进行分类--->将得到的结果训练回归器，得到(dx, dy, dw, dh)四个结果，并通过IOU值判断该框内的物体是否满足任务需求。

**Faster-RCNN**
Faster-RCNN分为4个主要内容:
- 1. Conv-layers。作为一种CNN网络目标检测方法，Faster-RCNN首先使用一组基础的conv+relu+pooling层提取image的feature maps。该feature maps被共享用于后续RPN的和全连接层。
- 2. Region proposal networks。RPN网络用语生成region proposals。该层通过softmax判断anchors属于positive或者negative，再利用bounding box regression修正anchors获得精确的proposals。
- 3. roi pooling。该层收集feature maps和proposas，综合这些信息提取proposal feature maps，送入后续全连接层判断目标类别。
- 4. classification。利用proposal feature maps计算proposal类别，同时再次bounding box regression获得检测框的精确位置。

**RPN算法流程**: 
- 1. 最后一个卷积层输出的特征图再进行一次卷积操作(也就是RPN层)得到新的特征图。
- 2. 新的特征图在平面上有40 * 60共2400个点，每个点都可以对应到原始图片上，得到9个anchor，所以一共可以得到40 * 60 * 9大约20000个候选区域。
- 3. 计算所有候选区域的scores
- 4. 把所有超出图片的候选区域都限制咋图片区域内，选scores最大的前12000个候选区域。
- 5. 剩余的区域中有些候选区域更前提候选区有很大的重叠，然后基于第4步的scores，采用非极大值抑制(NMS)。固定NMS的IoU阈值为0.7。然后再选出scores最大的前2000个候选区域。这2000个候选区域如果与某个标定区域重叠比例大于0.7 记为正样本。如果与任意一个标定区域重叠比例都小于0.3，记为负样本。
- 6. 在训练RPN层分类回归任务时，会随机地抽取256个区域来训练，正负候选区域的比例为1:1，如果正样本数小于128，用负样本填充。
- 7. 训练最后输出的分类回归任务时，随机抽取64个与真实标注框IoU>=0.5的区域作为前景，256-64个IoU<0.5切>=0.1的区域作为背景来训练。

**Faster-RCNN训练流程**: 
- 1. 使用ImageNet模型初始化，独立训练一个RPN网络
- 2. 仍然哟个ImageNet模型初始化，但是使用上一步RPN网络产生的proposal作为输入，训练一个Fast-RCNN网络
- 3. 使用第2步的Fast-RCNN网络参数初始化一个新的额RPN2网络，但是把RPN2、Fast-RCNN共享的那些卷积层的learning rate设置为0，也就是不更新，仅仅更新RPN2特有的那些网络层，重新训练
- 4. 仍然固定RPN2、Fast-RCNN共享的那些网络层面，把Fast-RCNN特有的网络层也加入进来，形成一个统一的网络，继续训练，fine tune Fast-RCNN特有的网络层

**流程**: 图片--->通过ImageNet网络提取图片特征，并得到相应的特征图--->通过RPN层，使用RPN算法得到特征图的候选区域--->每个候选区域得到一个分类器和回归器，分类器进行二分类，判断该候选区域内是否有目标物体，回归器得到dx,dy,dw,dh4个值，分别代表框的中心点坐标和框的宽和高--->然后将候选区域接着往下传，继续训练分类器和回归器，使用softmax分了得到N+1个类别，回归器会得到dx,dy,dw, dh4个值。

## 49. RCNN和Fast-RCNN的趋避
RCNN和Fast-RCNN把bbox Regression放进了神经网络内部，与region分类合并成了一个锅multitask模型。RCNN和Fast-RCNN使用的都是SS算法，但是该算法有个缺点就是只能在CPU撒好难过进行训练，这样就限制了神经网络的训练速度。而Fast-RCNN算法加入了一个专门生成候选区域的神经网络RPN(region proposal network)，这样的话就可以把找候选框的工作也交给神经网络来做了。Faster-RCNN可以简单的看做是”区域生成网络 + Faster-RCNN“的系统。用区域生成网络代替Faster-RCNN中的SS算法。

## 50. SSD算法
**特征金字塔**: 在不同的卷积层会输出不同大小的feature map(这是因为有pooling层的存在，他会将图片的尺寸变小)，而不同的feature map中含有不同的特征，而不同的特征，不同的特征可能对检测有不同的作用。总的来说，浅层卷积层可以得到物体的边缘信息，而深层网络可以得到更细节更抽象的特征。
**SSD**: SSD是在VGG16网络上发展来的，但是在VGG16的第五个(最后一个)卷积层之后使用了一次空洞卷积。这样做的目的是为了不使特征图的感受野变大，从而保留相对较小的感受野，这样就能检测到更小的目标。而且在不同尺寸的feature map上提取不同尺寸的特征映射，同时在不同的特征映射上面进行预测，它在增加运算量的同时可能会提高检测精度，因为它考虑了更多尺寸的特征。同时在不同特征的feature map上的每个点获取6个(有的层是4个)不同的bounding box，然后将这些bounding box结合起来，最后经过NMS处理最后的bounding box。图片在被送进网络之后先生成一系列的feature map，然后生成一些列的default box(筛选prior boxes投入训练)，然后一prior box为初始bbox，将bboxes回归到正确的GT位置上去，预测出的定位信息实际上是回归的bboxes和回归线的(prior box)的相对坐标。整个过程通过网络的一次前项传播就能完成。其中default box是指在feature map的每个单元格(cell)上都有一些固定大小的box，SSD图像中的groundtruth需要赋予到那些固定输出的boxes上。SSD的一个核心是同时采用lower的feature maps做检测。Default box就是预设一些目标预选框，后续通过softmax分类+bounding box regression获得真实目标的位置。prior box是指在实际中选择的要投入训练过程中的Default box(每个feature map cell不是k个default box都取)

## 51. YOLOv1算法
- **结构**: 
  YOLOv1是在GoogleNet上修改而来的，其核心思想就是利用整张图作为网络的输入，将目标检测作为回归问题解决，直接在输出层给出回归预选框的位置及其所属类别。YOLO最左边的是一个InceptionV1网络，共20层。InceptionV1提取的特征图再经过4个卷积2个全连接层，最后生成7*7*30的输出。
  
  YOLO将一副448*448的原图分割成7*7的网格，每个网格要预测两个大小形状不同的boudning box的坐标(x, y, w, h)和box内是否包含物体置信度confidence(每个bounding box都有一个confidence，该置信度只是为了表达box内有无物体的概率，不预测物体属于 哪一类)，x和y表示box中心点与该格子边界的相对值，w和h表示预测框box的宽度和高度相对于政府图像的宽度和高度的比例。(x, y, w, h)会限制在[0, 1]之间。与训练数据集上标定的物体真实坐标进行对比训练。以及物体属于20类别中每一类的概率(YOLO的训练数据为voc2012，它是一个20分类的数据集)。所以一个网格对应一个30(4*2-+2+20)维的向量。
  
- **YOLOv1预测工作流程**:
    - 1). 没个格子得到两个bounding boxes
    - 2). 每个网络预测的class信息和bounding boxes预测的confidence信息相乘，得到了每个bounding box预测具体物体的概率和位置重叠的概率PrIouPr(class|object) * Pr(object) * IoU = Pr(class) * Iou
    - 3). 对于每一个类别，对Pr|Iou进行排序，去除小于阈值的PrIoU，然后做非极大值抑制。

- **流程:** 图片--->将每张图片分成7*7的网格，每个网格会得到两个形状和大小都不同的bouding box--->每个网格会预测得到每个被需要预测的目标物体的类别信息，以及相应的confidence--->把每个类别的类别信息和confidence相乘得到的响应的IoU--->对每个类别得到的IoU进行排序--->去除其中低于设定的阈值的IoU，然后做极大值抑制

- **YOLOv1的缺点**: 
    - 1. 每个网格只对应两个bounding box，当物体的长宽比不常见(也就是训练数据覆盖不到时)，效果比较差
    - 2. 原始图片只划分为7*7的网格，当两个物体靠得很近时，效果比较差
    - 3. 最终每个网格只对应一个类别，容易出现漏检
    - 4. 对于图片中较小的物体，效果比较差


## 52. YOLOv2算法
**YOLO使用的是Google Net的自定制网络，比VGG16更快，但是精度略低于VGG16**
**YOLOv2使用的是修改版的Google Net，是在ImageNet上训练得来的**

**YOLOv2的改进**:
- 1>. YOLOv2首先修改预测分类网络的分辨率为448*448，ImageNet数据集上训练10个epoch。这个过程让网络有足够的时间去适应高分辨率的输入。
- 2>. YOLOv1使用全连接层数据进行bounding box进行预测。这会丢失较多的空间信息，导致定位不准。YOLOv2借鉴了Faster-RCNN中anchor的思想，即在卷积特征图上进行窗口滑动采样，每个中心预测9种不同大小的比例的anchor。总的来说就是移除全连接层(以获得跟过的空间信息)使用anchor boxes去预测bounding boxes。并且，YOLOv2由anchor box同时预测类别和坐标。
- 3>. YOLOv2中利用K-Means方法，通过对数据集中的ground truth box做聚类，找到ground truth box的统计规律。以聚类个数K为anchor boxes个数，以K个聚类中心box的宽和高为anchor box的宽和高。但是，随着K的增大，IoU也在增大(高召回率)，但是复杂度也在增加，所以平衡复杂度之后，最终得到的K值为5。
- 4>. 直接位置预测，使用anchor boxes的另一个问题是模型不稳定，YOLOv2位置预测值是预测边界框中心点相对应cell上角位置的相对偏移值，为了将边界框中心点约束在当前cell中，使用Sigmoid函数处理偏移值，这样预测值在(0, 1)范围内。

**Convolutional with Anchor Boxes的具体做法**:
- 1. 去掉最后的池化层呢个确保输出的卷积特征图有更高的分辨率
- 2. 缩减网络，让图片输入分辨率为416*416，目的是让后面产生的卷积特征图宽高都为几数，这样就可以产生一个center cell
- 3. 使用卷积层降采样，使得输入卷积网络的416*416图片最终得到13*13的卷积特征图
- 4. 由anchor box同时预测类别和坐标。因为YOLO是由每个cell来负责预测类别，每个cell对应的2个bounding box负责预测坐标。YOLOv2中，不再让类别的预测与每个cell绑定在一起，而是让全部放到anchor box中。

## 53. YOLOv3算法
- YOLOv3的的基础框架是Darknet-53，内部的网络主要为残差网络结构。
- YOLOv3有3个不同特征尺寸的输出，分别是13*13*255，26*26*255，52*52*255。
- YOLOv3一般使用416*416大小的图片作为输入，最后得到的特征图是13*13，再大些的特征图为26*26，再大些的图为52*52。
- YOLOv3同样采用K-Means聚类得到先验框的尺寸，每种下采样尺寸设定3种先验框，总共聚类9种尺寸的先验框。
- YOLOv3对类别预测函数进行了修改，没有再使用softmax，因为之前的分类网络种的softmax层都是建设一张图像或一个object属于一个类别，但是在复杂场景下，一个object可能属于多个类别，那么检测结果就应该是多标签分类。所以YOLOv3用逻辑回归来对每个类别做二分类。逻辑回归主要用Sigmoid函数，该函数可以将输入约束在0-1的范围内，因此当一张图像经过特征提取后的某一类输出经过Sigmoid核函数之后如果大于0.5，就表示属于该类，这样一个框就可以预测多个类别。并且使用的是交叉熵误差函数。

## 54. FCN算法
FCN算法接受任意尺寸的图像输入，采用转置卷积对最后一个卷积层高的feature map进行上采样，使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生一个预测，同时保留了原始输入图像中的空间信息，最后咋上采样的特征图上逐像素进行分类。

## 55. 语义分割的评价方式
**图像分割中通常使用许多标准衡量算法的精度。这些标准通常是像素精度IoU的变种**
- 第一种: PA(pixel Accuracy)像素精度，标记正确的像素占总像素的比例。
- 第二种: mPA(Mean Pixel Accuracy)均像素精度，计算每个类别被正确分类像素的比例，之后求所有类的平均。
- 第三种: MIoU(Mean Intersection over Uion): 均交并比，语义分割的标准度量，计算两个集合的交集和并集之比。在语义分割的问题中，这两个集合为真实值和预测值。每个类上计算IoU，之后平均
- 第四种: Frequency Weighted Intersection over Union(加权交并比): 是对MIou的改进，对每个类别按照重要性进行加权，重要性来自于出现的平率

## 56. Mask R-CNN(目标分割算法)
Mask R-CNN是一个实例(Instance segmentation)算法，可以用来做目标检测，目标实例分割，目标关键点检测。实例分割先要对一张图片所有的目标进行正确的检测同时还要对每个实例进行分割。检测的目的是把每个单个目标分类然后用bounding box标定出来；而实例分割的目的是区分每个像素不同的分类。整个Mask R-CNN算法的思路很简单，就是在原始Faster-RCNN的基础上增加了对应的Mask分支。

## 57. 1*1的卷积有何作用
- 增加非线性: 1*1卷积喝的卷积过程相当于全连接层的计算过程，并且还加入了非线性的激活函数，从而可以增加网络的非线性，使得网络可以表达更加复杂的特征。
- 特征降维: 通过控制卷积核的数量达到通道数大小的缩放。特征降维带来的好处是可以减少参数和计算量。

## 58. 什么是转置卷积
转置卷积就是通过卷积的逆过程。但是在深度学习中并不常用。虽然名为反卷积，却不是真正意义上额反卷积。转置卷积是一种上采样的方式，可以让图片变成大图片。

## 59. selective search 算法的步骤
**ss算法的主要作用是用来在目标检测的过程中生成候选区域**
- 1、计算区域集R里每个相邻区域的相似度(S1, S2, ...)
- 2、找出相似度最高的两个区域，让其河滨岗位新集RT，并添加进R
- 3、从S中移除所有与step2中有关的子集
- 4、重新计算新集Rt与所有子集的相似度(这里的相似度主要考虑颜色，纹理，尺寸，交叠四个方面)

## 60. YOLOv4算法
**网络结构**: YOLOv4网络主要由三个部分组成，一共161层。首先是CSPDarknet53主干网络，是整个网络的入口，输入图像首先会经过该网络。然后会通过SPP层和PANet层，最后经过YOLOv3Head的输出结果，这里的结果包括初始化的预测框的位置信息和检测目标的得分信息等，得到的结果处理后才能得出最终的结果。

**分为三个部分**: 
- 1、骨干网络提取: CSPDarkNet53，CSPDarkNet53是在YOLOv3的DarkNet结构每个大残差块上加上CSP(Cross Stage Partial)，其可以加强CNN的学习能力，能够在轻量化的同时确保准确性、降低计算瓶颈、降低内存成本。输入图像从CSPDarkNet出来应该有三个部分的结果，其中最后一部分的结果会经过SPP网络，将经过SPP网络输出的结果和第一、第二部分的结果在PANNet网络融合及上次阿阳和下采样。
- 2、特征金字塔: SPP(Spatial Pyramid Pooling，即空间金字塔池化)，SPP网络的作用是增加网咯的感受野，但不会改变输入图像的尺寸。
- 3、PANet: 在经过SPP后，通过融合三个卷积层后开始进入PANet部分。将三个部分的特征融合在一起，同样也会得到3个输出结果，用于预测针对不同大小的物体。

**相对于YOLOv3的提升**: 
YOLOv4是一种单阶段目标检测算法，该算法在YOLOv3的基础上添加了一些新的改进思路，使得其速度与精度都得到了极大的提升，具体包括:
- 1、输入端: 在模型训练阶段，做了一些改进，主要包括Mosaic数据增强，cmBN、STA自对抗训练。
- 2、BackBone基准网络: 融合了其它检测的一些新思路，主要包括CSPDarkNet53、Mish激活函数、Dropblock解决过拟合方法。
- 3、Neck中间层:目标检测网络在backBone与最后的Head输出层之间往往会插入一些层，YOLOv4中添加了SPP模块，FPN+PAN结构。
- 4、Head输出层: 输出层的锚框机制与YOLOv3相同，主要改进的是训练时损失函数CIOU_Loss，以及预测筛选的DIOU_nms。

## 61. YOLOv4和YOLOv3的区别
**YOLOv4和YOLOv3都是通过三个特征层来进行分类和预测**

**改进**:
- 1、主干特征由YOLOv3的DarkNet53改为CSPDarkNet53，主要在残差块进行了改进，引入了大残差。
- 2、加入了SPP和PANNet网络，用来增强图像的特征提取量，反复提取特征，并且SPP网络也可以增加感受野。
- 3、在激活函数方面，从YOLOv3的Leak_relu函数，改为在YOLOv4中使用新的Mish激活函数(Mish激活函数是一种自正则的单调神经网络激活函数，平滑的激活函数允许更好的信息深入神经网络，从而得到更好的准确性和泛化。)
- 4、YOLOv4还采用Mosaic数据增强，CIOU，学习率余弦衰减，标签平滑防止过拟合等操作。

## 62. YOLOv5
**YOLOv5是一种单阶段目标检测算法，该算法在YOLOv4的基础上增加了一些新的改进思路，使得速度和精度都得到了极大的提升，包括**:
- 输入端的Mosaic数据增强
- 自适应锚框计算
- 自适应图片缩放操作
- 基准端的Focus结构和CSP结构
- Neck端的SPP与FPN+PAN结构
- 输出端的损失函数GIOU_LOSS以及预测框筛选的DIOU_nms

**YOLOv5相对YOLOv4的改进**:
- 输入端: 在模型训练阶段，提出了一些改进思路，主要包括Mosaic数据增强，自适应锚框，自适应图片缩放。
- 基准网络: 在原始的CSDarknet53网络的基础上融合其它算法中的一些新思路，主要包括Focus结构和CSP结构。
- Neck网络: 目标检测网络在BackBone与最后的Head输出层之间往往会插入一些层，YOLOv5中添加了FPN+PAN结构。利用它可以进一步提升特征的多样性及鲁棒性
- Head输出层: 输出层的锚框机制与YOLOv4相同，主要改进的事训练时的损失函数GIOU_Loss，以及预测筛选的DIOU_nms。

**Mosaic数据增强**: YOLOv5在模型训练阶段仍然使用过了Mosaic数据增强的算法，该算法在CutMix数据增强方法的基础上改进而来。CutMix仅仅使用了两张图片进行拼接，而Mosaic数据增强方法才用过了4张图片，并且按照顺序随机缩放，随机裁剪和随机排布的方式进行拼接而成。这种增强方法可以将几张图片组合成一张，这样可以丰富数据集的同时极大的提升网络的训练速度，而且可以降低模型的内存。

**自适应锚框计算**: 在YOLO系列算法中，针对不同的数据集，都需要设定特定长度的锚点框。在网络训练阶段，模型在初始锚点框的基础上输出对应的预测框，计算其与GT框之间的差距，并执行反向更新操作，从而更新整个网络参数，因此设定初始锚点是比较关键的一环。在YOLOv3、YOLOv4检测算法中，训练不同的数据集时，根据数据集的名称自适应的计算出最佳的锚点框。

**自适应图片的缩放**: 针对不同的目标检测算法而言，通常需要执行图片的缩放操作，即将原始的输入图片缩放到一个固定的尺寸，再将其送入到检测网络中。原始的缩放方法存在一些问题，由于在实际使用中的很多图片的长宽比不同，因此缩放填充之后，两端的黑边大小不同，然而如果填充的过多，则会存在大量信息冗余，从而影响整个算法的推理速度。所以YOLOv5提出了能够自适应图片的缩放方式，具体步骤为: 1. 根据原始图片大小与输入到网络图片大小计算需要缩放的比较。2. 根据原始图片的大小与缩放比例计算缩放后的图片大小。3. 计算黑边填充值。

**Focus**: 该结构的主要思想格式通过slice操作来对输入图片进行裁剪。

**CSP结构**: YOLOv4网络中，借鉴了CSPNet的设计思路，仅仅在主干网络中设计了CSP结构。而YOLOv5中设计了两种CSP结构，以YOLOv5网络为例，CSP1_X结构应用于Backboone主干网络中，另一种CSP2_X结构应用于Neck网络中。

**Neck**: FPN+PAN-YOLOv5的Neck网络仍然使用了FPN+PAN结构，但是在它的基础上做了一些改进，YOLOv4的Neck结构中国，采用的是普通的卷积操作。而YOLOv5的Neck网络中，采用借鉴了CSPNet设计的CSP2结构，从而增强网络特征融合能力。

**Head**: GIoU_Loss-YOLOv5中采用GIoU_Loss做Bounding box的损失函数。

## 63. YOLO的后处理问题。

## 64. Attention和self-Attention的区别

## 65. 对比学习

## 66. Transform

## 67. 常见的loss函数

